{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://habr.com/ru/company/mlclass/blog/247751/]\n",
    "#### Введение в машинное обучение с помощью Python и Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pima-indians-diabetes\n",
    "6     Pregnancies\n",
    "148   Glucose\n",
    "72    BloodPressure\n",
    "35    SkinThickness\n",
    "0     Insulin\n",
    "33.6  BMI\n",
    "0.627 DiabetesPedigreeFunction\n",
    "50    Age\n",
    "1     Class\n",
    "Этот набор данных описывает медицинские записи индейцев пима и показывает, будет ли у каждого пациента возникать диабет в течение пяти лет.\n",
    "Описание полей следующее:\n",
    "preg = количество беременных\n",
    "Plas = концентрация глюкозы в плазме через 2 часа при оральном тесте на толерантность к глюкозе\n",
    "прес = диастолическое артериальное давление (мм рт.ст.)\n",
    "Кожа = Толщина кожной складки трицепса (мм)\n",
    "тест = 2-часовой сывороточный инсулин (мю Ед / мл)\n",
    "масса = индекс массы тела (вес в кг / (рост в м) ^ 2)\n",
    "pedi = диабет родословной\n",
    "возраст = возраст (лет)\n",
    "класс = переменная класса (1: положительный тест на диабет, 0: отрицательный тест на диабет)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первую очередь данные необходимо загрузить в оперативную память, чтобы мы имели возможность работать с ними. Сама библиотека Scikit-Learn использует в своей реализации NumPy массивы, поэтому будем загружать *.csv файлы средствами NumPy. Загрузим один из датасетов из репозитория UCI Machine Learning Repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "# url with dataset\n",
    "# url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "raw_data = pd.read_csv('data/pima-indians-diabetes.csv')\n",
    "# download the file\n",
    "# raw_data = urlopen(url)\n",
    "# load the CSV file as a numpy matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.842243</td>\n",
       "      <td>120.859192</td>\n",
       "      <td>69.101695</td>\n",
       "      <td>20.517601</td>\n",
       "      <td>79.903520</td>\n",
       "      <td>31.990482</td>\n",
       "      <td>0.471674</td>\n",
       "      <td>33.219035</td>\n",
       "      <td>0.348110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.370877</td>\n",
       "      <td>31.978468</td>\n",
       "      <td>19.368155</td>\n",
       "      <td>15.954059</td>\n",
       "      <td>115.283105</td>\n",
       "      <td>7.889091</td>\n",
       "      <td>0.331497</td>\n",
       "      <td>11.752296</td>\n",
       "      <td>0.476682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                6         148          72          35           0        33.6  \\\n",
       "count  767.000000  767.000000  767.000000  767.000000  767.000000  767.000000   \n",
       "mean     3.842243  120.859192   69.101695   20.517601   79.903520   31.990482   \n",
       "std      3.370877   31.978468   19.368155   15.954059  115.283105    7.889091   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   32.000000   32.000000   \n",
       "75%      6.000000  140.000000   80.000000   32.000000  127.500000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "            0.627          50           1  \n",
       "count  767.000000  767.000000  767.000000  \n",
       "mean     0.471674   33.219035    0.348110  \n",
       "std      0.331497   11.752296    0.476682  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243500   24.000000    0.000000  \n",
       "50%      0.371000   29.000000    0.000000  \n",
       "75%      0.625000   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas_profiling\n",
    "# pandas_profiling.ProfileReport(raw_data)\n",
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head\n",
    "dataset = raw_data\n",
    "# dataset.head()\n",
    "# dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      6  148  72  35    0  33.6  0.627\n",
       "0     1   85  66  29    0  26.6  0.351\n",
       "1     8  183  64   0    0  23.3  0.672\n",
       "2     1   89  66  23   94  28.1  0.167\n",
       "3     0  137  40  35  168  43.1  2.288\n",
       "4     5  116  74   0    0  25.6  0.201\n",
       "..   ..  ...  ..  ..  ...   ...    ...\n",
       "762  10  101  76  48  180  32.9  0.171\n",
       "763   2  122  70  27    0  36.8  0.340\n",
       "764   5  121  72  23  112  26.2  0.245\n",
       "765   1  126  60   0    0  30.1  0.349\n",
       "766   1   93  70  31    0  30.4  0.315\n",
       "\n",
       "[767 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "dataset = pd.DataFrame(raw_data)\n",
    "# separate the data from the target attributes\n",
    "X = dataset.iloc[:,:7]\n",
    "# X = dataset[:,:7]\n",
    "y = dataset.iloc[:,8]\n",
    "# y = dataset[:,:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее во всех примерах будем работать с этим набором данных, а именно с матрицей обьект-признак X и значениями целевой переменной y.\n",
    "#### Нормализация данных\n",
    "Всем хорошо знакомо, что большинство градиентных методов (на которых по-сути и основаны почти все алгоритмы машинного обучения) сильно чуствительны к шкалированию данных. Поэтому перед запуском алгоритмов чаще всего делается либо нормализация, либо так называемая стандартизация. Нормализация предполагает замену номинальных признаков так, чтобы каждый из них лежал в диапазоне от 0 до 1. Стандартизация же подразумевает такую предобработку данных, после которой каждый признак имеет среднее 0 и дисперсию 1. В Scikit-Learn уже есть готовые для этого функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# normalize the data attributes\n",
    "normalized_X = preprocessing.normalize(X)\n",
    "# standardize the data attributes\n",
    "standardized_X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12604006 0.27987607 0.11985899 0.08670605 0.08579532 0.16101595\n",
      " 0.14070756]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, y)\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False False False  True  True]\n",
      "[1 2 3 5 4 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(X, y)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       500\n",
      "           1       0.74      0.55      0.63       267\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       767\n",
      "   macro avg       0.77      0.72      0.74       767\n",
      "weighted avg       0.77      0.78      0.77       767\n",
      "\n",
      "[[449  51]\n",
      " [120 147]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       500\n",
      "           1       0.69      0.60      0.64       267\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       767\n",
      "   macro avg       0.75      0.73      0.73       767\n",
      "weighted avg       0.76      0.77      0.76       767\n",
      "\n",
      "[[429  71]\n",
      " [108 159]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       500\n",
      "           1       0.77      0.63      0.69       267\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       767\n",
      "   macro avg       0.79      0.77      0.78       767\n",
      "weighted avg       0.80      0.81      0.80       767\n",
      "\n",
      "[[449  51]\n",
      " [ 98 169]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# fit a k-nearest neighbor model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       267\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       767\n",
      "   macro avg       1.00      1.00      1.00       767\n",
      "weighted avg       1.00      1.00      1.00       767\n",
      "\n",
      "[[500   0]\n",
      " [  0 267]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       267\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       767\n",
      "   macro avg       1.00      1.00      1.00       767\n",
      "weighted avg       1.00      1.00      1.00       767\n",
      "\n",
      "[[500   0]\n",
      " [  0 267]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "# fit a SVM model to the data\n",
    "model = SVC()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
      "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'alpha': array([1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 0.e+00])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "0.28158141247308044\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "# from sklearn.grid_search import GridSearchCV  # OLD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# prepare a range of alpha values to test\n",
    "alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(X, y)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
      "          estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "          fit_params=None, iid='warn', n_iter=100, n_jobs=None,\n",
      "          param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001B8262B0B00>},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n",
      "0.28158140483146743\n",
      "0.9996839908911314\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn.linear_model import Ridge\n",
    "# from sklearn.grid_search import GridSearchCV  # OLD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'alpha': sp_rand()}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100)\n",
    "rsearch.fit(X, y)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
